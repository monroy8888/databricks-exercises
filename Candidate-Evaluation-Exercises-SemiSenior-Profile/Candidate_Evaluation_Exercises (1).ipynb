{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "569d36ca-503b-470a-94b4-192be0515161",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Candidate Evaluation Exercises for SemiSenior Profile\n",
    "\n",
    "This notebook contains exercises designed to evaluate a candidate's proficiency in Python programming, PySpark data processing, and AWS Cloud data solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08a0d5df-4c79-401d-9bb5-4ac2c438eadd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Python Programming Exercise\n",
    "\n",
    "**Task:** Write a Python class that represents a simple bank account. The class should have methods to deposit, withdraw, and check the balance, with basic error handling for withdrawal limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72df144-bff6-46a6-a9b3-fe4e8a3be778",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class StandarBankOperations:\n",
    "  \n",
    "  def __init__(self, name:str, bank:str):\n",
    "    self.name = name\n",
    "    self.bank = bank\n",
    "    self.deposit_register = []\n",
    "    self.withdraw_register = []\n",
    "    self.total_amount = 0\n",
    "\n",
    "  def deposit(self, amount:int):\n",
    "    try:\n",
    "      if amount:\n",
    "        self.deposit_register.append(amount)\n",
    "        self.total_amount += amount\n",
    "    except ValueError as e:\n",
    "      raise f'No amount value : {e}'\n",
    "    \n",
    "\n",
    "  def withdraw(self, amount:int):\n",
    "    try:\n",
    "      if amount and self.total_amount >= amount:\n",
    "        self.withdraw_register.append(amount)\n",
    "        self.total_amount -= amount\n",
    "      else:\n",
    "        print(f\"there's not enough money in the account\")\n",
    "    except ValueError as e:\n",
    "      raise f'No amount value : {e}'\n",
    "\n",
    "  def balance(self):\n",
    "\n",
    "    return   {'name': self.name,\n",
    "              'bank': self.bank,\n",
    "              'depositRegister':[x for x in self.deposit_register],\n",
    "              'withdrawRegister':[x for x in self.withdraw_register],\n",
    "              'TotalAmount': self.total_amount}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e00533b-3c6d-49c8-aabb-c8401121388c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Bancolombia(StandarBankOperations):\n",
    "    def __init__(self, name:str):\n",
    "        super().__init__(name, 'Bancolombia')\n",
    "        self.__withdrawLimits = 300\n",
    "\n",
    "    def withdraw(self, amount:int):\n",
    "        try:\n",
    "            if amount and self.total_amount >= self.__withdrawLimits:\n",
    "                self.withdraw_register.append(amount)\n",
    "                self.total_amount -= amount\n",
    "            else:\n",
    "                print(f\"there's not enough money in the account\")\n",
    "        except ValueError as e:\n",
    "            raise f'No amount value : {e}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510c06ac-ea6c-4211-987f-6c812b1a2ad1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clientone = Bancolombia(\"Sergio\")\n",
    "clientone.deposit(2030)\n",
    "clientone.deposit(2030)\n",
    "clientone.deposit(2030)\n",
    "clientone.withdraw(300)\n",
    "print(clientone.balance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5226ba04-066f-4d63-abb5-1897e4cf164e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## PySpark Data Processing Exercise\n",
    "\n",
    "**Task:** Given a PySpark DataFrame `df` with columns `name` and `salary`, write a PySpark query to calculate the average salary and filter out individuals earning more than the average salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56445066-c34b-474c-9fc9-04823b72ee3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f6578a-b107-458c-80b1-22186cb863d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "url_kaggle = 'https://www.kaggle.com/datasets/sazidthe1/data-science-salaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e09779f-11cd-4e5c-aac5-8a8f113b3958",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c00de0df-d9e1-4c8d-9802-4582b48563ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!echo '{\"username\":\"sergioquiroga0101\",\"key\":\"0000000000\"}' > ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd1fdcf-8962-4b61-9a98-f91c28438a8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465798d0-72e8-491b-a313-4bb7cc2d4e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "api.dataset_download_files('sazidthe1/data-science-salaries', path='./', unzip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af4ba46e-87a8-4f99-9697-c873c075d515",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816b85f8-9984-4c5f-9e97-522164223360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.option('header','true').csv('file:/Workspace/Repos/saquiroga85@misena.edu.co/databricks-exercises/Candidate-Evaluation-Exercises-SemiSenior-Profile/data_science_salaries.csv')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfcde0ce-ccf0-4ea1-a4dc-2116824fb830",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> Given a PySpark DataFrame df with columns name and salary, write a PySpark query to calculate the average salary and filter out individuals earning more than the average salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61b88066-c895-4cf0-acf4-755cdd23121d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_avg = df.agg(avg(col('salary')).alias('avg'))\n",
    "df_avg_head = df_avg.head()\n",
    "df_filter = df.filter(col('salary') > df_avg_head[0])\n",
    "df_filter = df_filter.select('job_title', 'salary').orderBy('salary')\n",
    "df_filter.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9181ad2e-17eb-4e9a-b640-5cbddce95465",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## AZURE Cloud Data Solutions Exercise\n",
    "\n",
    "**Task:** Design a cloud-based data pipeline using AZURE services that ingests, processes, and visualizes large datasets. The solution should ensure data security, be cost-effective, and scale based on demand.\n",
    "\n",
    "### Detailed Requirements\n",
    "1. **Data Ingestion:** \n",
    "2. **Data Storage:** \n",
    "3. **Data Processing:** \n",
    "4. **Data Visualization:** \n",
    "5. **Security and Compliance:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14d3eae8-5dc4-4846-933c-3922081c7157",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Detailed Requirements\n",
    "1. **Data Ingestion:** \n",
    "Data Factory : Allow me to ingest the Data in automatic way from differente sources and differents types of data, in adition save the data in specific format in the storage account threfore create all the pipeline .\n",
    "2. **Data Storage:** \n",
    "Data Storage: Allow me to create Blob Storage or containers in order to save the data, initiali I need to create a storage account.\n",
    "3. **Data Processing:** \n",
    "Databricks: Allow me to use differents tools like pyspark, python, sql etc. to procces the data, in addition allow me to connect to the blob storages in order to get the data.\n",
    "4. **Data Visualization:** \n",
    "PowerBI: Its native form microsoft and allow me to connect easyly to the data that comes from the DB in order to visualice it.\n",
    "5. **Security and Compliance:**\n",
    "KeyValut : To save important credentials and do not expose it in the databricks notebook\n",
    "IAM: To Allow me to give permission to different users or resources like Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fea6f6a-763b-40c6-9531-60139459ba2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cbdf4d9-f3f7-4c7a-a406-86877c8ac416",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Candidate_Evaluation_Exercises (1)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
